{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "source: Wikipedia\n",
    "\n",
    "In statistics, Decision tree learning uses a decision tree (as a predictive model) to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modeling approaches used in statistics, data mining and machine learning. Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures, leaves represent class labels and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.\n",
    "\n",
    "In decision analysis, a decision tree can be used to visually and explicitly represent decisions and decision making. In data mining, a decision tree describes data (but the resulting classification tree can be an input for decision making).\n",
    "\n",
    "https://en.wikipedia.org/wiki/Decision_tree_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "golf_data = pd.read_csv('golf_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset length:', len(golf_data))\n",
    "print('Data shape:', golf_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "golf_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le_outlook = preprocessing.LabelEncoder()\n",
    "le_outlook.fit(golf_data['outlook'].unique())\n",
    "le_temp = preprocessing.LabelEncoder()\n",
    "le_temp.fit(golf_data['temperature'].unique())\n",
    "le_hum = preprocessing.LabelEncoder()\n",
    "le_hum.fit(golf_data['humidity'].unique())\n",
    "le_windy = preprocessing.LabelEncoder()\n",
    "le_windy.fit(golf_data['windy'].unique())\n",
    "le_play = preprocessing.LabelEncoder()\n",
    "le_play.fit(golf_data['play'].unique())\n",
    "\n",
    "le_golf_data = pd.DataFrame()\n",
    "\n",
    "le_golf_data['outlook'] = le_outlook.transform(golf_data['outlook'])\n",
    "le_golf_data['temperature'] = le_temp.transform(golf_data['temperature'])\n",
    "le_golf_data['humidity'] = le_hum.transform(golf_data['humidity'])\n",
    "le_golf_data['windy'] = le_windy.transform(golf_data['windy'])\n",
    "le_golf_data['play'] = le_play.transform(golf_data['play'])\n",
    "le_golf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini \n",
    "\n",
    "Used by the CART (classification and regression tree) algorithm for classification trees, Gini impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset.  \n",
    "\n",
    "The Gini impurity can be computed by summing the probability $p_{i}$ of an item with label $ i$ being chosen times the probability $ \\sum _{k\\neq i}p_{k}=1-p_{i}$ of a mistake in categorizing that item. It reaches its minimum (zero) when all cases in the node fall into a single target category.\n",
    "\n",
    "To compute Gini impurity for a set of items with $ J$ classes, suppose $ i\\in \\{1,2,...,J\\}$, and let $ p_{i}$ be the fraction of items labeled with class $ i in the set.\n",
    "\n",
    "$ \\operatorname {I} _{G}(p)=\\sum _{i=1}^{J}p_{i}\\sum _{k\\neq i}p_{k}=\\sum _{i=1}^{J}p_{i}(1-p_{i})=\\sum _{i=1}^{J}(p_{i}-{p_{i}}^{2})=\\sum _{i=1}^{J}p_{i}-\\sum _{i=1}^{J}{p_{i}}^{2}=1-\\sum _{i=1}^{J}{p_{i}}^{2}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
